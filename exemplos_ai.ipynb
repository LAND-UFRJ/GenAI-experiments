{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo do que fizemos em IA até agora, somente aplicações práticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\",base_url='')\n",
    "\n",
    "len(embeddings.embed_query(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo báisco de Tool Calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model_tool = ChatOllama(model='llama3.2',base_url='',temperature=0)\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "def sub(a, b):\n",
    "    return a - b\n",
    "def mul(a, b):\n",
    "    return a * b\n",
    "def div(a, b):\n",
    "    return a / b\n",
    "\n",
    "tools = [add, sub, mul, div]\n",
    "model_tool = model_tool.bind_tools(tools)\n",
    "query = \"What is 3 + 2? \"\n",
    "response = model_tool.invoke(query).tool_calls\n",
    "\n",
    "for call in response:\n",
    "    name,args = call['name'], call['args']\n",
    "    result = eval(name)(**args)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "def evaluate_operation(operation):\n",
    "    name = operation['name']\n",
    "    parameters = operation['parameters']\n",
    "    \n",
    "    # Recursively evaluate any nested operations in the parameters\n",
    "    for key, value in parameters.items():\n",
    "        if isinstance(value, dict) and 'name' in value and 'parameters' in value:\n",
    "            parameters[key] = evaluate_operation(value)\n",
    "    \n",
    "    # Evaluate the operation with the processed parameters\n",
    "    return eval(name)(**parameters)\n",
    "\n",
    "\n",
    "query2 = \"What is 3 + 2? Take the result and multiply by 2\"\n",
    "\n",
    "messages = [SystemMessage('''\n",
    "If you need to apply a funtion to the result of another one, you should do as such: {'name':'function1','parameters':{'a':1,'b':{'name':'function2','parameters':{'a':1,'b':2}}}}'''),HumanMessage(query2)]\n",
    "\n",
    "response = model_tool.invoke(messages)\n",
    "messages.append(AIMessage(str(response.content)))\n",
    "package = response.content.split(';')\n",
    "print(package)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for x in package:\n",
    "    operation = eval(x)  # Convert JSON string to dictionary\n",
    "    result = evaluate_operation(operation)\n",
    "    print(result)\n",
    "    #messages.append(AIMessage(str(result)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de processamento de Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "client = ollama.Client(host='')\n",
    "\n",
    "response = client.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['plano_de_fundo.jpg']\n",
    "    }]\n",
    ")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de RAG com chroamDB\n",
    "Estamos migrando para milvusDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(host='')\n",
    "print(chroma_client.list_collections())\n",
    "collection = chroma_client.get_collection('genie_normal')\n",
    "collection.query(\n",
    "    query_texts=['SSID'],\n",
    "    n_results=4,\n",
    "    include=['documents']\n",
    ")['documents'][0]\n",
    "\n",
    "#usamos a llama localmente para para embeddings, 5a feira eu mostro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstração Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genieacs\n",
    "def change(parameter:str, value:str):\n",
    "    device_id = '5091E3-EX141-2237011003026'\n",
    "    acs = genieacs.Connection\n",
    "    print(f\"Changing parameter {parameter} to {value}\")\n",
    "    acs.task_set_parameter_values(device_id, [[parameter, value]])\n",
    "    print (f\"Parameter {parameter} changed to {value}\")\n",
    "\n",
    "def get(parameter:str):\n",
    "    device_id = '5091E3-EX141-2237011003026'\n",
    "    acs = genieacs.Connection\n",
    "    acs.device_get_parameter(device_id, parameter)\n",
    "    print(f\"The parameter {parameter} is {acs.device_get_parameter(device_id, parameter)}\")\n",
    "\n",
    "\n",
    "# adatação de PROMPT\n",
    "query = 'Change the name of the wifi network to \"MyWifi\"'\n",
    "collection = chroma_client.get_collection('genie_normal')\n",
    "text = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=4,\n",
    "    include=['documents']\n",
    ")['documents'][0]\n",
    "print(text)\n",
    "\n",
    "\n",
    "#Passa contexto para o modelo\n",
    "system_message = SystemMessage(content=f'Here are your instructuions: {text}')\n",
    "human_message = HumanMessage(content=query)\n",
    "#print(llm.invoke([system_message,human_message]).content)\n",
    "\n",
    "#Chama a função\n",
    "tools = [change,get]\n",
    "llm_tool = llm.bind_tools(tools)\n",
    "response = llm_tool.invoke([system_message,human_message])\n",
    "print(response)\n",
    "package = response.content.split(';')\n",
    "\n",
    "#Interpreta a Funçaõ\n",
    "for x in package:\n",
    "    x= eval(x)\n",
    "    name , param = x['name'], x['parameters']\n",
    "    result = eval(name)(**param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
